# Required API Keys
ANTHROPIC_API_KEY="your-anthropic-api-key" # Needed if proxying *to* Anthropic
OPENAI_API_KEY="sk-..."
GEMINI_API_KEY="your-google-ai-studio-key"

# Optional: Provider Preference and Model Mapping
# Controls which provider (google, openai, or anthropic) is preferred for mapping haiku/sonnet.
# Defaults to openai if not set.
# Set to "anthropic" for "just an Anthropic proxy" mode (no remapping)
PREFERRED_PROVIDER="openai"
OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Specify the exact models to map haiku/sonnet to.
# If PREFERRED_PROVIDER=google, these MUST be valid Gemini model names known to the server.
# Defaults to gemini-2.5-pro and gemini-2.5-flash if PREFERRED_PROVIDER=google.
# Defaults to gpt-4.1 and gpt-4.1-mini if PREFERRED_PROVIDER=openai.
# These are IGNORED when PREFERRED_PROVIDER=anthropic (models are not remapped).
# BIG_MODEL="gpt-4.1"
# SMALL_MODEL="gpt-4.1-mini"

# Example Google mapping:
# PREFERRED_PROVIDER="google"
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Example Google with vertex AI auth via ADC:
# PREFERRED_PROVIDER="google"
# USE_VERTEX_AUTH=true
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Example "just an Anthropic proxy" mode:
# PREFERRED_PROVIDER="anthropic"
# (BIG_MODEL and SMALL_MODEL are ignored in this mode)

# Optional: Force all backend requests to use a specific model.
# If set, every request to the backend will use this model, regardless of what the client sends.
# You can provide a provider-prefixed model (e.g. openai/gpt-4.1, gemini/gemini-2.5-pro, anthropic/claude-3-7-sonnet-20250219)
# or a bare model name (the proxy will add a prefix based on known lists or PREFERRED_PROVIDER).
# FORCE_MODEL="openai/gpt-4.1"
